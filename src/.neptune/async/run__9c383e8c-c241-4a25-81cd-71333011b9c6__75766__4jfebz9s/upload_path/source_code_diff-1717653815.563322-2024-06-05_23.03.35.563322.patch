diff --git a/runs/mlruns/0/c6068a4a9bf745548741aa3b76ed22a1/meta.yaml b/runs/mlruns/0/c6068a4a9bf745548741aa3b76ed22a1/meta.yaml
index c06ecd3..b3a90f8 100644
--- a/runs/mlruns/0/c6068a4a9bf745548741aa3b76ed22a1/meta.yaml
+++ b/runs/mlruns/0/c6068a4a9bf745548741aa3b76ed22a1/meta.yaml
@@ -1,5 +1,5 @@
 artifact_uri: /Users/rishimalhotra/projects/cv/image_classification/repo_hub/sandbox_repo/runs/mlruns/0/c6068a4a9bf745548741aa3b76ed22a1/artifacts
-end_time: null
+end_time: 1717389721862
 entry_point_name: ''
 experiment_id: '0'
 lifecycle_stage: active
@@ -10,6 +10,6 @@ source_name: ''
 source_type: 4
 source_version: ''
 start_time: 1717388809272
-status: 1
+status: 3
 tags: []
 user_id: rishimalhotra
diff --git a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.1 b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.1
index 166be3c..f213f4e 100644
Binary files a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.1 and b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.1 differ
diff --git a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.2 b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.2
index 5602c2b..9b2641e 100644
Binary files a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.2 and b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/loss_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.2 differ
diff --git a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.3 b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.3
index f612b32..795b535 100644
Binary files a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.3 and b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_train/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.3 differ
diff --git a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.4 b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.4
index 72f713f..5faccbf 100644
Binary files a/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.4 and b/runs/tensorboard/100_by_100_images_and_deeper_net_with_higher_lr/top_k_accuracy_val/events.out.tfevents.1717388829.MacBook-Pro-3.local.32483.4 differ
diff --git a/src/data_setup.py b/src/data_setup.py
index dbf0d58..58ae93f 100644
--- a/src/data_setup.py
+++ b/src/data_setup.py
@@ -66,9 +66,9 @@ def get_class_names_from_folder_names(classes: list[str]):
 
 def create_mini_datasets(train_dir: str, val_dir: str, classes: list[str], transform: torchvision.transforms.Compose):
     mini_train_dataset = SubsetImageFolder(
-        root=train_dir, classes=classes, num_samples_per_class=1000, transform=transform)
+        root=train_dir, classes=classes, num_samples_per_class=10, transform=transform)
     mini_val_dataset = SubsetImageFolder(
-        root=val_dir, classes=classes, num_samples_per_class=50, transform=transform)
+        root=val_dir, classes=classes, num_samples_per_class=10, transform=transform)
 
     assert len(mini_train_dataset) > 0, "Training dataset is empty"
     assert len(mini_val_dataset) > 0, "Validation dataset is empty"
diff --git a/src/engine.py b/src/engine.py
index 3c6f7c3..aa17b2e 100644
--- a/src/engine.py
+++ b/src/engine.py
@@ -96,12 +96,10 @@ def train(model: torch.nn.Module,
             model, train_dataloader, loss_fn, optimizer, device)
         val_step_dict = test_step(model, val_dataloader, loss_fn, device)
 
-        run_manager.track_metrics({
-            'loss': {'train': train_step_dict["loss"], 'val': val_step_dict["loss"]},
-            'top_k_accuracy': {'train': train_step_dict["top_k_accuracy"], 'val': val_step_dict["top_k_accuracy"]}
-        }, epoch)
+        run_manager.log_metrics({"train/loss": train_step_dict["loss"],
+                                 "val/loss": val_step_dict["loss"],
+                                 "train/accuracy": train_step_dict["top_k_accuracy"],
+                                 "val/accuracy": val_step_dict["top_k_accuracy"]}, epoch)
 
         if epoch != 0 and (epoch % checkpoint_interval == 0 or epoch == epoch_end - 1):
             run_manager.save_model(model, epoch)
-
-    run_manager.end_run()
diff --git a/src/run_manager.py b/src/run_manager.py
index 001f4da..18461a2 100644
--- a/src/run_manager.py
+++ b/src/run_manager.py
@@ -1,9 +1,15 @@
+import io
 import os
-import mlflow
 import torch
 from torch.utils.tensorboard.writer import SummaryWriter
 from pathlib import Path
-from typing import Dict
+from typing import Dict, Any
+import matplotlib.pyplot as plt
+import PIL.Image as Image
+import neptune
+import yaml
+import shutil
+config = yaml.safe_load(open("config.yaml"))
 
 
 class RunManager:
@@ -11,37 +17,80 @@ class RunManager:
     The job of the run manager is to manage experiment runs. It integrates
     '''
 
-    def __init__(self, run_dir: str, run_id: str):
-        self.run_id = run_id
-        self.writer = SummaryWriter(log_dir=f"{run_dir}/tensorboard/{run_id}")
-        self.temp_checkpoints_dir = Path(f"{run_dir}")
+    def __init__(self, run_name: str):
+        self.run_id = run_name
+        self.temp_dir = Path("temp")
+        self.temp_dir.mkdir(exist_ok=True)
 
-        self.temp_checkpoints_dir.mkdir(parents=True,
-                                        exist_ok=True)
+        self.run = neptune.init_run(
+            project="towards-hi/image-classification",
+            api_token=config["neptune_api_token"],
+            name=run_name
+        )
 
-    def track_metrics(self, metrics: Dict[str, Dict[str, float]], epoch: int) -> None:
+    def log_data(self, data: Dict[str, Any]) -> None:
         """
-        Track metrics for the run and plot it on tensorboard.
+        Log data to the run.
+
+        Args:
+          data: a dictionary of data to log.
+
+        Example:
+          data = {
+            "num_epochs": 10,
+            "learning_rate": 0.001,
+            "batch_size": 32,
+            "hidden_units": 512,
+            "loss_fn": "CrossEntropyLoss",
+            "optimizer": "Adam",
+            "device": "cuda"
+          }
+        """
+        for key in data:
+            self.run[key] = data[key]
+
+    def log_files(self, files: Dict[str, str]) -> None:
+        """
+        Log files to the run.
+
+        Args:
+          files: a dictionary of files to log.
+
+        Example:
+          files = {
+            "model/code": "model_builder.py"
+          }
+        """
+        for key in files:
+            self.run[key].upload(files[key])
+
+    def log_metrics(self, metrics: Dict[str, float], epoch: int) -> None:
+        """
+        Track metrics for the run and plot it on neptune.
 
         Args:
           metrics: a dictionary of metrics to track.
 
         Example:
           metrics = {
-            'loss': {'train': 0.1, 'val': 0.2},
-            'accuracy': {'train': 0.9, 'val': 0.8}
+            "train/loss": 0.5,
+            "val/loss": 0.3,
+            "train/accuracy": 0.8,
+            "val/accuracy": 0.9
           }
         """
 
-        for metric_name, metric_dict in metrics.items():
-            self.writer.add_scalars(metric_name, metric_dict, epoch)
-            print(f"\nEpoch: {epoch}, {metric_name}: {metric_dict}")
-
-            # writer.add_scalar('training/train_loss', train_loss, epoch)
-        # writer.add_scalar('training/val_loss', test_loss, epoch)
+        for metric_name in metrics:
+            self.run[metric_name].append(metrics[metric_name], step=epoch)
+            # print(f"\nEpoch: {epoch}, {metric_name}: {metrics[metric_name]}")
 
     def end_run(self):
-        self.writer.close()
+        self.run.stop()
+        try:
+            shutil.rmtree(self.temp_dir)
+
+        except Exception as e:
+            print(f"Failed to remove directory: {e}")
 
     def save_model(self, model: torch.nn.Module, epoch: int) -> None:
         """Saves a PyTorch model to a target directory.
@@ -53,16 +102,13 @@ class RunManager:
         Example usage:
           save_model(model=model_0, epoch=5)
         """
-        model_save_path = self.temp_checkpoints_dir / f"{epoch}.pth"
 
-        # Save the model state_dict()
-        print(f"[INFO] Saving model to: {model_save_path}")
-        torch.save(obj=model.state_dict(),
-                   f=model_save_path)
-        mlflow.log_artifact(str(model_save_path), artifact_path="checkpoints")
-        os.remove(model_save_path)
+        model_save_path = self.temp_dir / f"{epoch}.pth"
+        print(f"[INFO] Saving model to {model_save_path}")
+        torch.save(obj=model.state_dict(), f=model_save_path)
+        self.run[f"checkpoints/{epoch}.pth"].upload(str(model_save_path))
 
-    def load_checkpoint_if_it_exists(self, model: torch.nn.Module, checkpoint_path: str) -> int:
+    def load_checkpoint(self, model: torch.nn.Module, run_id: str, checkpoint_path: str) -> int:
         """
         Loads a PyTorch model weights from a run at an epoch.
         Args:
@@ -72,18 +118,25 @@ class RunManager:
         Example usage:
           load_model(model=model_0, epoch=5)
         """
-        if checkpoint_path is None:
-            # checkpoint_path = self.checkpoints_dir / f"{self.run_id}.pth"
-            print(f"[INFO] Not loading model")
-            return 0
-
-        if not Path(checkpoint_path).exists():
-            print(f"[INFO] Checkpoint not found at: {checkpoint_path}")
-            return 0
-
-        print(f"[INFO] Loading checkpoint from: {checkpoint_path}")
-        checkpoint_run_id = checkpoint_path.split("/")[-2]
-        epoch_start = int(checkpoint_path.split("/")[-1].split(".")[0])
-        params = torch.load(checkpoint_path)
-        model.load_state_dict(params)
-        return epoch_start
+        run = neptune.init_run(with_id="NLI-8", mode="read-only")
+        run[checkpoint_path].download(destination=str(self.temp_dir))
+
+        # params = torch.load(str(self.temp_dir / "model.pth"))
+
+        # TODO: implement
+        # pass
+        # if checkpoint_path is None:
+        #     # checkpoint_path = self.checkpoints_dir / f"{self.run_id}.pth"
+        #     print(f"[INFO] Not loading model")
+        #     return 0
+
+        # if not Path(checkpoint_path).exists():
+        #     print(f"[INFO] Checkpoint not found at: {checkpoint_path}")
+        #     return 0
+
+        # print(f"[INFO] Loading checkpoint from: {checkpoint_path}")
+        # checkpoint_run_id = checkpoint_path.split("/")[-2]
+        # epoch_start = int(checkpoint_path.split("/")[-1].split(".")[0])
+        # params = torch.load(checkpoint_path)
+        # model.load_state_dict(params)
+        return 1
diff --git a/src/train.py b/src/train.py
index a95df4b..4b163c0 100644
--- a/src/train.py
+++ b/src/train.py
@@ -1,5 +1,5 @@
 from run_manager import RunManager
-import mlflow
+
 import argparse
 import os
 import torch
@@ -60,7 +60,7 @@ def train(args) -> None:
         output_shape=len(class_names)
     ).to(args.device)
 
-    run_manager = RunManager(args.run_dir, args.run_id)
+    run_manager = RunManager(args.run_id)
     epoch_start = run_manager.load_checkpoint_if_it_exists(
         model, checkpoint_path=args.continue_from_checkpoint_path)
 
@@ -71,39 +71,38 @@ def train(args) -> None:
     optimizer = torch.optim.Adam(model.parameters(),
                                  lr=args.learning_rate)
 
-    with mlflow.start_run(run_name=args.run_id):
-        params = {
-            "num_epochs": args.num_epochs,
-            "learning_rate": args.learning_rate,
-            "batch_size": args.batch_size,
-            "hidden_units": args.hidden_units,
-            "loss_fn": "CrossEntropyLoss",
-            "optimizer": "Adam",
-            "device": args.device,
-        }
-        mlflow.log_params(params)
-
-        with open("model_summary.txt", "w") as f:
-            f.write(str(model))
-
-        mlflow.log_artifact("model_builder.py")
-        mlflow.log_artifact("model_summary.txt")
-        os.remove("model_summary.txt")
-
-        engine.train(model=model,
-                     train_dataloader=train_dataloader,
-                     val_dataloader=test_dataloader,
-                     optimizer=optimizer,
-                     loss_fn=loss_fn,
-                     epoch_start=epoch_start,
-                     epoch_end=epoch_start + args.num_epochs,
-                     run_manager=run_manager,
-                     checkpoint_interval=checkpoint_interval,
-                     device=args.device)
+    parameters = {
+        "num_epochs": args.num_epochs,
+        "learning_rate": args.learning_rate,
+        "batch_size": args.batch_size,
+        "hidden_units": args.hidden_units,
+        "loss_fn": "CrossEntropyLoss",
+        "optimizer": "Adam",
+        "device": args.device,
+    }
+
+    run_manager.log_data({"parameters": parameters,
+                          "model/summary": str(model),
+                          })
+
+    run_manager.log_files({"model/code": "model_builder.py"
+                           })
+
+    engine.train(model=model,
+                 train_dataloader=train_dataloader,
+                 val_dataloader=test_dataloader,
+                 optimizer=optimizer,
+                 loss_fn=loss_fn,
+                 epoch_start=epoch_start,
+                 epoch_end=epoch_start + args.num_epochs,
+                 run_manager=run_manager,
+                 checkpoint_interval=1,  # TODO: change back to checkpoint_interval
+                 device=args.device)
+
+    run_manager.end_run()
 
 
 if __name__ == "__main__":
-    mlflow.set_tracking_uri(config["mlflow_uri"])
 
     parser = argparse.ArgumentParser(
         prog='Computer Vision Model Trainer',
diff --git a/src/visualize.py b/src/visualize.py
index 5f16d83..f55c272 100644
--- a/src/visualize.py
+++ b/src/visualize.py
@@ -49,9 +49,8 @@ if __name__ == "__main__":
     #     model,
     #     epoch=29
     # )
-    checkpoint_path = ""
-    RunManager(config["run_dir"],
-               "random").load_checkpoint_if_it_exists(model, checkpoint_path)
+    checkpoint_path = "checkpoints/2.pth"
+    RunManager("").load_checkpoint(model, "IM-21", checkpoint_path)
 
     predict_on_random_images(model, mini_val_dataset,
                              class_names=class_names, n=5, seed=4200)
